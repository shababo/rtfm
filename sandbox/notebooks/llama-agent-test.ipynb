{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample Tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize llm\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ReAct agent\n",
    "agent = ReActAgent.from_tools([multiply_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_question = \"What is (121 * 3) + 42?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 3f434367-2bee-43dc-a53d-ffcfc22cd092. Step input: What is (121 * 3) + 42?\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_verify_locations cafile='/Users/loyalshababo/dev/rtfm/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/Users/loyalshababo/dev/rtfm/.venv/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\nYou have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools to complete each subtask.\\n\\nYou have access to the following tools:\\n> Tool Name: multiply\\nTool Description: multiply(a: int, b: int) -> int\\nMultiply two integers and returns the result integer\\nTool Args: {\"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"], \"type\": \"object\"}\\n\\n\\n\\n## Output Format\\n\\nPlease answer in the same language as the question and use the following format:\\n\\n```\\nThought: The current language of the user is: (user\\'s language). I need to use a tool to help me answer the question.\\nAction: tool name (one of multiply) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nNEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {\\'input\\': \\'hello world\\', \\'num_beams\\': 5}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools. I\\'ll use the user\\'s language to answer\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n## Current Conversation\\n\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n'}, {'role': 'user', 'content': 'What is (121 * 3) + 42?'}], 'model': 'gpt-3.5-turbo-1106', 'stream': False, 'temperature': 0.1}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\nYou have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools to complete each subtask.\\n\\nYou have access to the following tools:\\n> Tool Name: multiply\\nTool Description: multiply(a: int, b: int) -> int\\nMultiply two integers and returns the result integer\\nTool Args: {\"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"], \"type\": \"object\"}\\n\\n\\n\\n## Output Format\\n\\nPlease answer in the same language as the question and use the following format:\\n\\n```\\nThought: The current language of the user is: (user\\'s language). I need to use a tool to help me answer the question.\\nAction: tool name (one of multiply) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nNEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {\\'input\\': \\'hello world\\', \\'num_beams\\': 5}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools. I\\'ll use the user\\'s language to answer\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n## Current Conversation\\n\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n'}, {'role': 'user', 'content': 'What is (121 * 3) + 42?'}], 'model': 'gpt-3.5-turbo-1106', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16aa116a0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16aa116a0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x16a3bded0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x16a3bded0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a3d5be0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a3d5be0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 03 Sep 2024 00:09:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9sxjyovasqtkjsckdd4zcfcg'), (b'openai-processing-ms', b'613'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39444'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'834ms'), (b'x-request-id', b'req_4d62fc93e0a619ff66018cbd4e794c75'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ELQTW66lONqte.vkx3VFpETu4vDsPUEKWSTovP.wSwQ-1725322193-1.0.1.1-eSN.p_eplCH7ftE_tXiI7BijgcrSdNMMOchIPGjc45RWg0ses3VAUYcJ_wRyLUr7rd9pp1TG_FvaOQd1KlHGlQ; path=/; expires=Tue, 03-Sep-24 00:39:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=98Tt.KBbdsMDZB3q3c0q2jWxn8m.iZ2Z6WUc54anh8s-1725322193562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8bd18378baf69864-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 03 Sep 2024 00:09:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9sxjyovasqtkjsckdd4zcfcg'), (b'openai-processing-ms', b'613'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39444'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'834ms'), (b'x-request-id', b'req_4d62fc93e0a619ff66018cbd4e794c75'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ELQTW66lONqte.vkx3VFpETu4vDsPUEKWSTovP.wSwQ-1725322193-1.0.1.1-eSN.p_eplCH7ftE_tXiI7BijgcrSdNMMOchIPGjc45RWg0ses3VAUYcJ_wRyLUr7rd9pp1TG_FvaOQd1KlHGlQ; path=/; expires=Tue, 03-Sep-24 00:39:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=98Tt.KBbdsMDZB3q3c0q2jWxn8m.iZ2Z6WUc54anh8s-1725322193562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8bd18378baf69864-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Tue, 03 Sep 2024 00:09:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9sxjyovasqtkjsckdd4zcfcg'), ('openai-processing-ms', '613'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15552000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '200'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '199'), ('x-ratelimit-remaining-tokens', '39444'), ('x-ratelimit-reset-requests', '7m12s'), ('x-ratelimit-reset-tokens', '834ms'), ('x-request-id', 'req_4d62fc93e0a619ff66018cbd4e794c75'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ELQTW66lONqte.vkx3VFpETu4vDsPUEKWSTovP.wSwQ-1725322193-1.0.1.1-eSN.p_eplCH7ftE_tXiI7BijgcrSdNMMOchIPGjc45RWg0ses3VAUYcJ_wRyLUr7rd9pp1TG_FvaOQd1KlHGlQ; path=/; expires=Tue, 03-Sep-24 00:39:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=98Tt.KBbdsMDZB3q3c0q2jWxn8m.iZ2Z6WUc54anh8s-1725322193562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8bd18378baf69864-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Tue, 03 Sep 2024 00:09:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9sxjyovasqtkjsckdd4zcfcg'), ('openai-processing-ms', '613'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15552000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '200'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '199'), ('x-ratelimit-remaining-tokens', '39444'), ('x-ratelimit-reset-requests', '7m12s'), ('x-ratelimit-reset-tokens', '834ms'), ('x-request-id', 'req_4d62fc93e0a619ff66018cbd4e794c75'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ELQTW66lONqte.vkx3VFpETu4vDsPUEKWSTovP.wSwQ-1725322193-1.0.1.1-eSN.p_eplCH7ftE_tXiI7BijgcrSdNMMOchIPGjc45RWg0ses3VAUYcJ_wRyLUr7rd9pp1TG_FvaOQd1KlHGlQ; path=/; expires=Tue, 03-Sep-24 00:39:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=98Tt.KBbdsMDZB3q3c0q2jWxn8m.iZ2Z6WUc54anh8s-1725322193562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8bd18378baf69864-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_4d62fc93e0a619ff66018cbd4e794c75\n",
      "request_id: req_4d62fc93e0a619ff66018cbd4e794c75\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use the multiply tool to calculate 121 * 3, and then add 42 to the result.\n",
      "Action: multiply\n",
      "Action Input: {'a': 121, 'b': 3}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 363\n",
      "\u001b[0m> Running step 976ed5a6-3c48-4c1d-a24b-bf6b7848d52a. Step input: None\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\nYou have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools to complete each subtask.\\n\\nYou have access to the following tools:\\n> Tool Name: multiply\\nTool Description: multiply(a: int, b: int) -> int\\nMultiply two integers and returns the result integer\\nTool Args: {\"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"], \"type\": \"object\"}\\n\\n\\n\\n## Output Format\\n\\nPlease answer in the same language as the question and use the following format:\\n\\n```\\nThought: The current language of the user is: (user\\'s language). I need to use a tool to help me answer the question.\\nAction: tool name (one of multiply) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nNEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {\\'input\\': \\'hello world\\', \\'num_beams\\': 5}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools. I\\'ll use the user\\'s language to answer\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n## Current Conversation\\n\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n'}, {'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': \"Thought: The current language of the user is: English. I need to use the multiply tool to calculate 121 * 3, and then add 42 to the result.\\nAction: multiply\\nAction Input: {'a': 121, 'b': 3}\"}, {'role': 'user', 'content': 'Observation: 363'}], 'model': 'gpt-3.5-turbo-1106', 'stream': False, 'temperature': 0.1}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\nYou have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools to complete each subtask.\\n\\nYou have access to the following tools:\\n> Tool Name: multiply\\nTool Description: multiply(a: int, b: int) -> int\\nMultiply two integers and returns the result integer\\nTool Args: {\"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"], \"type\": \"object\"}\\n\\n\\n\\n## Output Format\\n\\nPlease answer in the same language as the question and use the following format:\\n\\n```\\nThought: The current language of the user is: (user\\'s language). I need to use a tool to help me answer the question.\\nAction: tool name (one of multiply) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nNEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {\\'input\\': \\'hello world\\', \\'num_beams\\': 5}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools. I\\'ll use the user\\'s language to answer\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: [your answer here (In the same language as the user\\'s question)]\\n```\\n\\n## Current Conversation\\n\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n'}, {'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': \"Thought: The current language of the user is: English. I need to use the multiply tool to calculate 121 * 3, and then add 42 to the result.\\nAction: multiply\\nAction Input: {'a': 121, 'b': 3}\"}, {'role': 'user', 'content': 'Observation: 363'}], 'model': 'gpt-3.5-turbo-1106', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 03 Sep 2024 00:09:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9sxjyovasqtkjsckdd4zcfcg'), (b'openai-processing-ms', b'694'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'198'), (b'x-ratelimit-remaining-tokens', b'39391'), (b'x-ratelimit-reset-requests', b'14m23.157s'), (b'x-ratelimit-reset-tokens', b'913ms'), (b'x-request-id', b'req_a9182b4f649566b0456bbc7f68082390'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8bd1837e0d9d9864-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 03 Sep 2024 00:09:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9sxjyovasqtkjsckdd4zcfcg'), (b'openai-processing-ms', b'694'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'198'), (b'x-ratelimit-remaining-tokens', b'39391'), (b'x-ratelimit-reset-requests', b'14m23.157s'), (b'x-ratelimit-reset-tokens', b'913ms'), (b'x-request-id', b'req_a9182b4f649566b0456bbc7f68082390'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8bd1837e0d9d9864-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 03 Sep 2024 00:09:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9sxjyovasqtkjsckdd4zcfcg', 'openai-processing-ms': '694', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '198', 'x-ratelimit-remaining-tokens': '39391', 'x-ratelimit-reset-requests': '14m23.157s', 'x-ratelimit-reset-tokens': '913ms', 'x-request-id': 'req_a9182b4f649566b0456bbc7f68082390', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8bd1837e0d9d9864-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 03 Sep 2024 00:09:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9sxjyovasqtkjsckdd4zcfcg', 'openai-processing-ms': '694', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '198', 'x-ratelimit-remaining-tokens': '39391', 'x-ratelimit-reset-requests': '14m23.157s', 'x-ratelimit-reset-tokens': '913ms', 'x-request-id': 'req_a9182b4f649566b0456bbc7f68082390', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8bd1837e0d9d9864-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_a9182b4f649566b0456bbc7f68082390\n",
      "request_id: req_a9182b4f649566b0456bbc7f68082390\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: (121 * 3) + 42 = 363\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(math_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121 * 3) + 42 = 363\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
